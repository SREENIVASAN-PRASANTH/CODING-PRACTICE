{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiwojEPpWtba5o6kRzLnjh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SREENIVASAN-PRASANTH/CODING-PRACTICE/blob/main/using_nltk_for_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NaX9dfjL-ZW3"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ],
      "metadata": {
        "id": "SWh7PmK4_GHO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0PEys1i_fTr",
        "outputId": "b7f45de7-450e-46d0-d5e4-8aa4087cc46c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"NlP is a way of replying like a human\"\n",
        "tokens = word_tokenize(text)\n",
        "print(f\"Tokens: {tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPo0F8v2_zVK",
        "outputId": "7a3732bb-a39c-4b09-df9c-005055bede59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['NlP', 'is', 'a', 'way', 'of', 'replying', 'like', 'a', 'human']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHtDTZQWAfzd",
        "outputId": "2fa6d8f3-1998-457f-e46c-3394d3a74335"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'only', 'or', 'do', \"won't\", 'had', 'how', 'wasn', 'has', 'this', 'these', 'why', 're', \"aren't\", 'yourself', 'didn', 'yourselves', 'most', \"wasn't\", 'don', 'needn', 'over', 'ourselves', 'then', 'his', 'what', 'above', 'more', 'can', 'down', \"didn't\", \"wouldn't\", 'both', 'same', 'if', 'nor', \"you're\", 'whom', 'm', 'on', 'when', 'not', 'up', 'couldn', \"hadn't\", 'just', 'while', 'am', 'at', 'no', 'doing', 'further', \"mightn't\", 'you', 'shan', 'themselves', 'as', \"that'll\", 'was', \"you'd\", 'i', 'doesn', 't', 'll', 'hasn', 'its', 'hers', 'y', 'your', 'having', 'under', 'yours', 'into', 'mustn', 'their', 'it', 'of', 'such', 'does', \"couldn't\", \"hasn't\", 'shouldn', 'who', 'with', 'been', 'they', 'is', 'after', 'own', 'too', 'were', 'should', 'for', 'until', 'than', 'very', 'won', \"you'll\", 'being', \"you've\", 'herself', \"shouldn't\", 've', 'isn', 'before', 'out', 'from', 'are', 'during', 'himself', 'd', 'wouldn', 'the', 'me', 'an', 'off', \"she's\", 'other', 'but', 'that', 'all', 'below', 'in', 'be', 'ma', \"needn't\", 'itself', 'there', 'any', 'hadn', 'weren', 'mightn', 'myself', 'against', \"doesn't\", 'haven', \"mustn't\", \"shan't\", 'o', \"weren't\", 'so', 'again', 'will', 'he', 'to', 'she', 'about', \"should've\", 'him', 'by', 'now', 'have', 'them', \"isn't\", \"haven't\", 'those', 'through', 'once', 'a', 'where', 'we', 'which', 'each', \"it's\", 'few', 'here', 'and', 'ours', 'our', 'theirs', 'ain', 'aren', 'did', 'some', 'because', 's', 'her', \"don't\", 'my', 'between'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "useful_words = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(useful_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7lfrPnRA-DO",
        "outputId": "0e99aeac-dfa2-4ce7-8ef3-61c2c38f05d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NlP', 'way', 'replying', 'like', 'human']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in useful_words]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pquXXR2CB37",
        "outputId": "f09103b1-c8f4-4190-e3cc-c6113df36a8d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nlp', 'way', 'repli', 'like', 'human']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "Lemmatized_words = [lemmatizer.lemmatize(word) for word in useful_words]\n",
        "print(Lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeU-MHembHC6",
        "outputId": "e10f3801-e881-481d-d576-a85008acde90"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NlP', 'way', 'replying', 'like', 'human']\n"
          ]
        }
      ]
    }
  ]
}